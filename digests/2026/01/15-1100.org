#+TITLE: HN Digest 2026-01-15 11:00:00 UT UTC
#+DATE: 2026-01-15T11:00:00Z
#+CURATOR: claude
#+SOURCE: https://hacker-news.firebaseio.com/v0/

* Vibe
Pi gets an AI brain, Safari learns masonry, and HN argues about RAG like it's 2023

* Highlights
- Pi AI Hat: $130 for 8GB of 'solution seeking problem'
- Handy: Free STT that keeps your secrets
- Sparrow-1: AI learns not to interrupt you mid-sentence

* Stories

** Raspberry Pi's New AI Hat Adds 8GB of RAM for Local LLMs :hardware:raspberrypi:ai:edge:
:PROPERTIES:
:ID:       46629682
:URL:      https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/
:HN_URL:   https://news.ycombinator.com/item?id=46629682
:POINTS:   72
:COMMENTS: 42
:BY:       ingve
:END:

*** TLDR
Raspberry Pi launched the $130 AI HAT+ 2 with a Hailo 10H chip and 8GB LPDDR4X RAM, capable of 40 TOPS at just 3W. In practice, it's underwhelming for LLMs since the CPU often outperforms the NPU, and 8GB is too small for serious models. Better suited for vision tasks like object detection.

*** Take
Raspberry Pi keeps throwing AI at the wall hoping something sticks. This is basically an expensive way to run worse inference than your laptop can manage.

*** Comments

**** buran77
:PROPERTIES:
:COMMENT_ID: 46629700
:END:
Raspberry lost the magic of the older Pis. They're just jumping into segments that are already filled with more qualified competition.

**** dwedge
:PROPERTIES:
:COMMENT_ID: 46629750
:END:
8GB RAM for AI on a Pi sounds underwhelming even from the headline.

**** t43562
:PROPERTIES:
:COMMENT_ID: 46629800
:END:
The presented usecase has been object detection from lots of video cameras in realtime. They seem very fast for spotting foxes and cats.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
树莓派新款AI扩展板为本地大语言模型增加8GB内存
***** TLDR
树莓派发布了售价130美元的AI HAT+ 2，搭载Hailo 10H芯片和8GB内存，功耗仅3W可达40 TOPS。实际运行大语言模型效果欠佳，CPU常常比NPU更快，8GB内存对正经模型来说太小了。更适合视觉任务如目标检测。
***** Take
树莓派一直在往墙上扔AI，希望能粘住点什么。这基本上是花大价钱买一个跑推理还不如你笔记本的东西。
***** Comments
- 树莓派失去了老款Pi的魔力。他们只是跳进了已经挤满了更强竞争对手的领域。
- 8GB内存跑AI，光看标题就觉得不够用。
- 它的使用场景是从多个摄像头实时检测物体。检测狐狸和猫挺快的。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Raspberry PiがローカルLLM向けに8GB RAMを搭載した新AIハットを発表
***** TLDR
Raspberry Piが130ドルのAI HAT+ 2を発売。Hailo 10Hチップと8GB LPDDR4X RAMを搭載し、3Wで40 TOPSを実現。実際にはLLMには力不足で、CPUの方がNPUより速いことも多い。8GBでは本格的なモデルには足りず、物体検出のような視覚タスク向け。
***** Take
Raspberry PiはAIを壁に投げ続けて何かがくっつくのを願っている。これは基本的にノートPCより劣る推理を高い金を払って動かす方法だ。
***** Comments
- Raspberry Piは古いPiの魔法を失った。競合で溢れているセグメントに飛び込んでいるだけ。
- 8GB RAMでPi上のAI、見出しだけで物足りなさそう。
- ユースケースは複数カメラからのリアルタイム物体検出。キツネや猫の検出はかなり速い。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
라즈베리 파이의 새 AI 햇, 로컬 LLM용 8GB RAM 추가
***** TLDR
라즈베리 파이가 130달러짜리 AI HAT+ 2를 출시했다. Hailo 10H 칩과 8GB LPDDR4X RAM을 탑재해 3W로 40 TOPS를 달성한다. 실제로 LLM에는 부족하고 CPU가 NPU보다 빠른 경우도 많다. 8GB는 제대로 된 모델에는 작아서 물체 감지 같은 비전 작업에 더 적합하다.
***** Take
라즈베리 파이는 계속 AI를 벽에 던지면서 뭔가 붙기를 바라고 있다. 이건 기본적으로 노트북보다 못한 추론을 비싸게 돌리는 방법이다.
***** Comments
- 라즈베리 파이는 옛날 Pi의 마법을 잃었다. 이미 경쟁자들로 가득 찬 분야에 뛰어들고 있을 뿐이다.
- Pi에서 AI용 8GB RAM이라니, 제목만 봐도 부족해 보인다.
- 유스케이스는 여러 카메라의 실시간 물체 감지다. 여우와 고양이 감지에는 꽤 빠르다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
El nuevo sombrero AI de Raspberry Pi añade 8GB de RAM para LLMs locales
***** TLDR
Raspberry Pi lanzó el AI HAT+ 2 de $130 con chip Hailo 10H y 8GB de RAM LPDDR4X, capaz de 40 TOPS a solo 3W. En la práctica, es decepcionante para LLMs ya que la CPU suele superar a la NPU, y 8GB es muy poco para modelos serios. Mejor para tareas de visión como detección de objetos.
***** Take
Raspberry Pi sigue lanzando IA a la pared esperando que algo pegue. Esto es básicamente una forma cara de ejecutar inferencia peor que la de tu portátil.
***** Comments
- Raspberry perdió la magia de los Pis antiguos. Solo están saltando a segmentos llenos de competencia más cualificada.
- 8GB de RAM para IA en un Pi suena decepcionante incluso desde el título.
- El caso de uso presentado es detección de objetos de muchas cámaras en tiempo real. Son muy rápidos para detectar zorros y gatos.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Raspberry Pis neuer AI Hat fügt 8GB RAM für lokale LLMs hinzu
***** TLDR
Raspberry Pi hat den $130 AI HAT+ 2 mit Hailo 10H-Chip und 8GB LPDDR4X RAM vorgestellt, der 40 TOPS bei nur 3W leistet. In der Praxis enttäuschend für LLMs, da die CPU oft schneller als die NPU ist und 8GB für ernsthafte Modelle zu wenig sind. Besser für Bildverarbeitung wie Objekterkennung.
***** Take
Raspberry Pi wirft weiter KI an die Wand in der Hoffnung, dass etwas kleben bleibt. Das ist im Grunde eine teure Art, schlechtere Inferenz als auf dem Laptop zu fahren.
***** Comments
- Raspberry hat die Magie der alten Pis verloren. Sie springen nur in Segmente, die bereits mit qualifizierter Konkurrenz gefüllt sind.
- 8GB RAM für KI auf einem Pi klingt schon in der Überschrift enttäuschend.
- Der präsentierte Anwendungsfall ist Echtzeit-Objekterkennung von vielen Kameras. Sie sind sehr schnell beim Erkennen von Füchsen und Katzen.
** Handy – Free open source speech-to-text app :opensource:stt:privacy:accessibility:
:PROPERTIES:
:ID:       46628397
:URL:      https://github.com/cjpais/Handy
:HN_URL:   https://news.ycombinator.com/item?id=46628397
:POINTS:   96
:COMMENTS: 54
:BY:       tin7in
:END:

*** TLDR
Handy is a free, open-source, cross-platform STT app that runs entirely offline. Press a hotkey to speak, release to transcribe, and it pastes text directly. Supports Whisper and Parakeet models with GPU acceleration. No cloud, no subscription, just works.

*** Take
Finally, an STT app that doesn't demand your credit card and firstborn child. The bar was underground and Handy barely cleared it.

*** Comments

**** blutoot
:PROPERTIES:
:COMMENT_ID: 46628450
:END:
I have dystonia which often stiffens my arms. TTS apps like SuperWhisper have proven very helpful. I am hoping to get a similar experience out of Handy.

**** kuatroka
:PROPERTIES:
:COMMENT_ID: 46628500
:END:
I had been searching for STT app for weeks. Every single app was either paid or had a monthly subscription. It felt ridiculous having to pay when it's all powered by such small models.

**** PhilippGille
:PROPERTIES:
:COMMENT_ID: 46628550
:END:
Has anyone compared this with OpenWhispr? From the description they seem very similar.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Handy – 免费开源语音转文字应用
***** TLDR
Handy是一款免费、开源、跨平台的语音转文字应用，完全离线运行。按快捷键说话，松开即转录，直接粘贴文本。支持Whisper和Parakeet模型，可GPU加速。无需云端，无需订阅，开箱即用。
***** Take
终于有一款STT应用不要你的信用卡和长子了。门槛低到地下，Handy勉强迈过去了。
***** Comments
- 我有肌张力障碍，手臂经常僵硬。像SuperWhisper这样的语音应用对我很有帮助。希望Handy也能有类似体验。
- 我找STT应用找了好几周。每个应用要么付费要么月订阅。明明都是小模型驱动的，还要收费太离谱了。
- 有人比较过这个和OpenWhispr吗？看描述它们很像。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Handy – 無料オープンソースの音声テキスト変換アプリ
***** TLDR
Handyは無料でオープンソースのクロスプラットフォームSTTアプリで、完全オフラインで動作する。ホットキーを押して話し、離すと文字起こしされ、直接テキストを貼り付ける。WhisperとParakeetモデルをサポートし、GPU高速化も可能。クラウド不要、サブスク不要、すぐ使える。
***** Take
ついにクレジットカードと長男を要求しないSTTアプリが登場。ハードルは地下にあったが、Handyはギリギリ超えた。
***** Comments
- 私はジストニアがあり、腕がよく硬くなる。SuperWhisperのようなTTSアプリはとても役立っている。Handyでも同様の体験ができればと思う。
- STTアプリを何週間も探していた。どれも有料か月額課金だった。こんな小さなモデルで動くのに課金するなんてばかげていた。
- これとOpenWhisprを比較した人はいる？説明を見る限りよく似ている。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Handy – 무료 오픈소스 음성-텍스트 앱
***** TLDR
Handy는 완전히 오프라인으로 작동하는 무료 오픈소스 크로스플랫폼 STT 앱이다. 단축키를 누르고 말하고, 떼면 받아쓰기되어 바로 텍스트가 붙여넣기된다. Whisper와 Parakeet 모델을 지원하며 GPU 가속도 가능하다. 클라우드 없음, 구독 없음, 그냥 작동한다.
***** Take
드디어 신용카드와 장남을 요구하지 않는 STT 앱이 나왔다. 기준이 땅 밑에 있었는데 Handy가 겨우 넘었다.
***** Comments
- 저는 근긴장이상이 있어서 팔이 자주 굳는다. SuperWhisper 같은 TTS 앱이 많이 도움됐다. Handy도 비슷한 경험을 주길 바란다.
- STT 앱을 몇 주간 찾았다. 전부 유료거나 월구독이었다. 작은 모델로 돌아가는데 돈을 내라니 말도 안됐다.
- 이거랑 OpenWhispr 비교해본 사람 있나? 설명 보면 매우 비슷해 보인다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Handy – Aplicación de voz a texto gratuita y de código abierto
***** TLDR
Handy es una aplicación STT gratuita, de código abierto y multiplataforma que funciona completamente offline. Pulsa una tecla rápida para hablar, suelta para transcribir y pega el texto directamente. Soporta modelos Whisper y Parakeet con aceleración GPU. Sin nube, sin suscripción, simplemente funciona.
***** Take
Por fin una app STT que no pide tu tarjeta de crédito y tu primogénito. El listón estaba bajo tierra y Handy apenas lo pasó.
***** Comments
- Tengo distonía que a menudo endurece mis brazos. Apps TTS como SuperWhisper me han ayudado mucho. Espero tener una experiencia similar con Handy.
- Estuve buscando apps STT durante semanas. Todas eran de pago o tenían suscripción mensual. Era ridículo pagar cuando funcionan con modelos tan pequeños.
- ¿Alguien ha comparado esto con OpenWhispr? Por la descripción parecen muy similares.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Handy – Kostenlose Open-Source Sprache-zu-Text App
***** TLDR
Handy ist eine kostenlose, quelloffene, plattformübergreifende STT-App, die komplett offline läuft. Hotkey drücken zum Sprechen, loslassen zum Transkribieren, und der Text wird direkt eingefügt. Unterstützt Whisper- und Parakeet-Modelle mit GPU-Beschleunigung. Keine Cloud, kein Abo, funktioniert einfach.
***** Take
Endlich eine STT-App, die nicht nach Kreditkarte und Erstgeborenem verlangt. Die Latte lag unterirdisch und Handy hat sie knapp geschafft.
***** Comments
- Ich habe Dystonie, die meine Arme oft versteift. TTS-Apps wie SuperWhisper haben sich als sehr hilfreich erwiesen. Ich hoffe, mit Handy eine ähnliche Erfahrung zu machen.
- Ich habe wochenlang nach einer STT-App gesucht. Jede war entweder kostenpflichtig oder hatte ein Monatsabo. Es war lächerlich, zu zahlen, wenn alles von so kleinen Modellen angetrieben wird.
- Hat jemand das mit OpenWhispr verglichen? Von der Beschreibung her scheinen sie sehr ähnlich zu sein.
** Show HN: Sparrow-1 – Audio-native model for human-level turn-taking without ASR :ai:audio:voice:startup:
:PROPERTIES:
:ID:       46619614
:URL:      https://www.tavus.io/post/sparrow-1-human-level-conversational-timing-in-real-time-voice
:HN_URL:   https://news.ycombinator.com/item?id=46619614
:POINTS:   73
:COMMENTS: 17
:BY:       code_brian
:END:

*** TLDR
Tavus released Sparrow-1, an audio model that predicts conversational 'floor ownership' rather than waiting for silence. It analyzes semantic completeness, prosodic cues, and vocal signals at frame-level to achieve zero interruptions with 55ms median latency. Claims 100% precision and recall in benchmarks.

*** Take
An AI that finally learned basic conversation etiquette. The benchmarks claim perfection which is exactly the kind of thing that makes you squint at the fine print.

*** Comments

**** ttul
:PROPERTIES:
:COMMENT_ID: 46619700
:END:
I tried talking to Claude today. What a nightmare. It constantly interrupts you. Without decent turn-taking, the AI seems impolite and it's just an icky experience.

**** cuuupid
:PROPERTIES:
:COMMENT_ID: 46619750
:END:
There is pretty much nobody working on latency and realtime at the level Tavus is. Sparrow-1 would be a defining achievement for most startups but will just be one of dozens for Tavus.

**** dfajgljsldkjag
:PROPERTIES:
:COMMENT_ID: 46619800
:END:
I am always skeptical of benchmarks that show perfect scores, especially when they come from the company selling the product.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Show HN: Sparrow-1 – 无需ASR实现人类级对话切换的原生音频模型
***** TLDR
Tavus发布了Sparrow-1，这是一个预测对话'话语权归属'而非等待静默的音频模型。它在帧级别分析语义完整性、韵律边界和声音信号，实现零打断，中位延迟55毫秒。基准测试声称100%精确率和召回率。
***** Take
一个终于学会基本对话礼仪的AI。基准测试声称完美，这正是让你眯起眼睛看小字的那种东西。
***** Comments
- 我今天试着和Claude对话。简直是噩梦。它不停打断你。没有好的话语切换，AI显得很不礼貌，体验很糟糕。
- 几乎没有人在延迟和实时处理上达到Tavus的水平。Sparrow-1对大多数初创公司来说是里程碑式成就，但对Tavus只是几十个成就之一。
- 我对声称完美分数的基准测试总是持怀疑态度，尤其是来自卖产品的公司。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Show HN: Sparrow-1 – ASR不要で人間レベルの会話ターンテイキングを実現する音声ネイティブモデル
***** TLDR
TavusがSparrow-1を発表。沈黙を待つのではなく会話の「フロア所有権」を予測するオーディオモデル。フレームレベルで意味的完結性、韻律境界、音声シグナルを分析し、中央値55msの遅延でゼロ割り込みを達成。ベンチマークでは100%の精度と再現率を主張。
***** Take
ついに基本的な会話マナーを学んだAI。ベンチマークが完璧を主張しているのは、まさに細かい注意書きを確認したくなる類のものだ。
***** Comments
- 今日Claudeと話してみた。悪夢だった。常に割り込んでくる。適切なターンテイキングがないと、AIは無礼に感じるし、不快な体験だ。
- Tavusほどのレベルでレイテンシとリアルタイム処理に取り組んでいる会社はほとんどない。Sparrow-1はほとんどのスタートアップにとって画期的な成果だが、Tavusにとっては数十の成果の一つに過ぎない。
- 完璧なスコアを示すベンチマークには常に懐疑的だ、特に製品を売っている会社からのものには。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Show HN: Sparrow-1 – ASR 없이 인간 수준의 대화 턴테이킹을 구현하는 오디오 네이티브 모델
***** TLDR
Tavus가 침묵을 기다리지 않고 대화의 '발언권 소유'를 예측하는 오디오 모델 Sparrow-1을 출시했다. 프레임 수준에서 의미적 완결성, 운율 경계, 음성 신호를 분석해 55ms 중간 지연으로 무중단을 달성한다. 벤치마크에서 100% 정밀도와 재현율을 주장한다.
***** Take
드디어 기본적인 대화 예절을 배운 AI다. 벤치마크가 완벽을 주장하는데, 이건 정확히 작은 글씨를 확인하고 싶어지는 종류의 것이다.
***** Comments
- 오늘 Claude와 대화해봤다. 악몽이었다. 계속 끼어든다. 적절한 턴테이킹 없이는 AI가 무례해 보이고 불쾌한 경험이다.
- Tavus 수준으로 지연시간과 실시간 처리를 연구하는 곳은 거의 없다. Sparrow-1은 대부분의 스타트업에게는 획기적인 성과지만 Tavus에게는 수십 개 중 하나일 뿐이다.
- 완벽한 점수를 보여주는 벤치마크에는 항상 회의적이다, 특히 제품을 파는 회사에서 나온 것은.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Show HN: Sparrow-1 – Modelo de audio nativo para turnos de conversación a nivel humano sin ASR
***** TLDR
Tavus lanzó Sparrow-1, un modelo de audio que predice la 'propiedad del turno' conversacional en lugar de esperar el silencio. Analiza la completitud semántica, señales prosódicas y vocales a nivel de frame para lograr cero interrupciones con 55ms de latencia media. Afirma 100% de precisión y recall en benchmarks.
***** Take
Un AI que finalmente aprendió etiqueta básica de conversación. Los benchmarks afirman perfección, que es exactamente el tipo de cosa que te hace entrecerrar los ojos para leer la letra pequeña.
***** Comments
- Probé hablar con Claude hoy. Una pesadilla. Te interrumpe constantemente. Sin turnos decentes, el AI parece maleducado y es una experiencia desagradable.
- Prácticamente nadie trabaja en latencia y tiempo real al nivel de Tavus. Sparrow-1 sería un logro definitorio para la mayoría de startups pero será solo uno de docenas para Tavus.
- Siempre soy escéptico de benchmarks que muestran puntuaciones perfectas, especialmente cuando vienen de la empresa que vende el producto.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Show HN: Sparrow-1 – Audio-natives Modell für menschliches Turn-Taking ohne ASR
***** TLDR
Tavus hat Sparrow-1 veröffentlicht, ein Audio-Modell, das konversationelle 'Floor-Ownership' vorhersagt statt auf Stille zu warten. Es analysiert semantische Vollständigkeit, prosodische Hinweise und Sprachsignale auf Frame-Ebene, um null Unterbrechungen bei 55ms medianer Latenz zu erreichen. Behauptet 100% Precision und Recall in Benchmarks.
***** Take
Eine KI, die endlich grundlegende Gesprächsetikette gelernt hat. Die Benchmarks behaupten Perfektion, was genau die Art von Sache ist, bei der man das Kleingedruckte prüfen möchte.
***** Comments
- Ich habe heute versucht, mit Claude zu sprechen. Ein Albtraum. Es unterbricht ständig. Ohne ordentliches Turn-Taking wirkt die KI unhöflich und es ist eine unangenehme Erfahrung.
- Es gibt praktisch niemanden, der auf dem Niveau von Tavus an Latenz und Echtzeit arbeitet. Sparrow-1 wäre für die meisten Startups eine prägende Leistung, wird aber nur eine von Dutzenden für Tavus sein.
- Ich bin immer skeptisch bei Benchmarks, die perfekte Werte zeigen, besonders wenn sie von der Firma kommen, die das Produkt verkauft.
** The <Geolocation> HTML Element :web:privacy:html:standards:
:PROPERTIES:
:ID:       46612711
:URL:      https://developer.chrome.com/blog/geolocation-html-element
:HN_URL:   https://news.ycombinator.com/item?id=46612711
:POINTS:   55
:COMMENTS: 36
:BY:       enz
:END:

*** TLDR
Chrome proposes a new <geolocation> HTML element that requires explicit user clicks instead of JS API calls. It shows a visible button users must interact with, enforces styling constraints to prevent clickjacking, and provides autolocate and watch modes. Aims to reduce permission fatigue and accidental blocks.

*** Take
Web standards committee reinvents the 'ask before tracking' button. The fact that this requires a spec instead of just not being creepy about location is peak modern web.

*** Comments

**** mkl
:PROPERTIES:
:COMMENT_ID: 46612800
:END:
This might be easier than refusing permission every time. I don't use anything that needs a precise location, and I don't ever want to share my actual location.

**** marginalia_nu
:PROPERTIES:
:COMMENT_ID: 46612850
:END:
This seems pretty sketchy, and I don't really understand what prevents a website from clickjacking.

**** crote
:PROPERTIES:
:COMMENT_ID: 46612900
:END:
I'm confused about how it actually works. If clicking on it does trigger a location permission prompt: what's the point?

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
<Geolocation> HTML元素
***** TLDR
Chrome提议新增<geolocation> HTML元素，需要用户显式点击而非JS API调用。它显示一个用户必须交互的可见按钮，强制样式约束防止点击劫持，并提供自动定位和监视模式。旨在减少权限疲劳和误点拒绝。
***** Take
Web标准委员会重新发明了'跟踪前询问'按钮。这需要一个规范而不是简单地不要对位置那么变态，这就是现代Web的巅峰。
***** Comments
- 这可能比每次都拒绝权限更容易。我不用任何需要精确位置的东西，也从不想分享我的真实位置。
- 这看起来很可疑，我不太明白什么能阻止网站进行点击劫持。
- 我对它实际如何工作感到困惑。如果点击它确实触发位置权限提示：那意义何在？
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
<Geolocation> HTML要素
***** TLDR
ChromeがJS API呼び出しではなく明示的なユーザークリックを必要とする新しい<geolocation> HTML要素を提案。ユーザーが操作する必要のある可視ボタンを表示し、クリックジャッキングを防ぐスタイル制約を強制し、自動位置取得とウォッチモードを提供する。許可疲れと誤ブロックを減らすことが目的。
***** Take
Web標準委員会が「追跡前に聞く」ボタンを再発明した。単に位置情報について気持ち悪くならなければいいだけなのに仕様が必要というのが、まさに現代Webの極みだ。
***** Comments
- 毎回許可を拒否するよりこれの方が楽かもしれない。正確な位置情報を必要とするものは使っていないし、実際の位置を共有したくない。
- これはかなり怪しく見えるし、何がクリックジャッキングを防ぐのかよく分からない。
- 実際どう動くのか混乱している。クリックで位置許可プロンプトが出るなら、何の意味がある？
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
<Geolocation> HTML 요소
***** TLDR
Chrome이 JS API 호출 대신 명시적인 사용자 클릭이 필요한 새로운 <geolocation> HTML 요소를 제안한다. 사용자가 상호작용해야 하는 눈에 보이는 버튼을 표시하고, 클릭재킹을 방지하기 위한 스타일 제약을 적용하며, 자동 위치 확인과 감시 모드를 제공한다. 권한 피로와 실수로 인한 차단을 줄이는 것이 목표다.
***** Take
웹 표준 위원회가 '추적 전에 물어보기' 버튼을 재발명했다. 그냥 위치에 대해 소름끼치게 굴지 않으면 되는데 규격이 필요하다는 게 현대 웹의 정점이다.
***** Comments
- 매번 권한을 거부하는 것보다 이게 더 쉬울 수 있다. 정확한 위치가 필요한 건 안 쓰고, 실제 위치를 공유하고 싶지도 않다.
- 이거 꽤 수상해 보이고, 뭐가 클릭재킹을 막는지 잘 모르겠다.
- 실제로 어떻게 작동하는지 혼란스럽다. 클릭하면 위치 권한 프롬프트가 뜨면: 무슨 의미가 있지?
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
El elemento HTML <Geolocation>
***** TLDR
Chrome propone un nuevo elemento HTML <geolocation> que requiere clics explícitos del usuario en lugar de llamadas a la API JS. Muestra un botón visible con el que los usuarios deben interactuar, aplica restricciones de estilo para prevenir clickjacking, y proporciona modos de autolocalización y seguimiento. Busca reducir la fatiga de permisos y los bloqueos accidentales.
***** Take
El comité de estándares web reinventa el botón de 'preguntar antes de rastrear'. El hecho de que esto requiera una especificación en lugar de simplemente no ser espeluznante con la ubicación es el pico de la web moderna.
***** Comments
- Esto podría ser más fácil que rechazar el permiso cada vez. No uso nada que necesite ubicación precisa, y nunca quiero compartir mi ubicación real.
- Esto parece bastante sospechoso, y no entiendo qué previene el clickjacking de un sitio web.
- Estoy confundido sobre cómo funciona realmente. Si hacer clic activa un aviso de permiso de ubicación: ¿cuál es el punto?
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Das <Geolocation> HTML-Element
***** TLDR
Chrome schlägt ein neues <geolocation> HTML-Element vor, das explizite Benutzerklicks statt JS-API-Aufrufe erfordert. Es zeigt einen sichtbaren Button, mit dem Benutzer interagieren müssen, erzwingt Styling-Einschränkungen gegen Clickjacking und bietet Autolocate- und Watch-Modi. Ziel ist die Reduzierung von Berechtigungsmüdigkeit und versehentlichen Blocks.
***** Take
Das Web-Standards-Komitee erfindet den 'Vor dem Tracken fragen'-Button neu. Dass dies eine Spezifikation erfordert, statt einfach nicht gruselig bei Standortdaten zu sein, ist der Höhepunkt des modernen Webs.
***** Comments
- Das könnte einfacher sein als jedes Mal die Berechtigung abzulehnen. Ich nutze nichts, das einen genauen Standort braucht, und will meinen echten Standort nie teilen.
- Das scheint ziemlich fragwürdig, und ich verstehe nicht, was eine Website am Clickjacking hindert.
- Ich bin verwirrt, wie es tatsächlich funktioniert. Wenn ein Klick einen Standortberechtigungs-Prompt auslöst: Was ist der Sinn?
** Ask HN: How are you doing RAG locally? :ai:rag:search:llm:
:PROPERTIES:
:ID:       46616529
:URL:      https://news.ycombinator.com/item?id=46616529
:HN_URL:   https://news.ycombinator.com/item?id=46616529
:POINTS:   167
:COMMENTS: 62
:BY:       tmaly
:END:

*** TLDR
HN discusses local RAG setups. Top approaches: SQLite-vec and FAISS for vectors, BM25 for code (embeddings are bad for code), hybrid search combining both. Key insight: you probably don't need a fancy vector DB - SQLite FTS5 or plain trigram search often works better for specific use cases.

*** Take
Every six months HN rediscovers that grep still works. The actual answer to 'how do I do RAG' is 'do you actually need RAG or do you just want to feel like you're doing AI?'

*** Comments

**** codebolt
:PROPERTIES:
:COMMENT_ID: 46616600
:END:
Giving the LLM tools with an OData query interface has worked well for me. At work we have an Excel sheet with 40k rows which the LLM was able to quickly and reliably analyse.

**** __jf__
:PROPERTIES:
:COMMENT_ID: 46616650
:END:
For vector generation I started using Meta-LLama-3-8B with Python and Transformers on an RTX-A6000. Fast but noisy and burns 500W. Switched to M1 Ultra with MLX - same speed, less heat.

**** beklein
:PROPERTIES:
:COMMENT_ID: 46616700
:END:
Most of my complex documents are Markdown files. I can recommend github.com/tobi/qmd. It's a simple CLI tool for searching these kinds of files. Better results than fzf.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Ask HN: 你们怎么在本地做RAG？
***** TLDR
HN讨论本地RAG方案。主流方法：向量用SQLite-vec和FAISS，代码用BM25（向量对代码效果差），混合搜索结合两者。关键发现：你可能不需要花哨的向量数据库——SQLite FTS5或简单的三元组搜索对特定场景往往效果更好。
***** Take
HN每六个月就会重新发现grep仍然管用。'怎么做RAG'的真正答案是'你真的需要RAG还是只是想感觉自己在做AI？'
***** Comments
- 给LLM配备OData查询接口的工具对我很有效。工作中有个4万行的Excel表，LLM能快速可靠地分析。
- 向量生成我最初用Meta-LLama-3-8B配Python和Transformers跑在RTX-A6000上。快但吵且烧500W。换成M1 Ultra配MLX后——同样快，发热少。
- 我大部分复杂文档是Markdown文件。推荐github.com/tobi/qmd。这是个简单的CLI工具用来搜索这类文件。比fzf效果好。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Ask HN: ローカルでRAGをどうやっている？
***** TLDR
HNがローカルRAGのセットアップを議論。主なアプローチ：ベクター用にSQLite-vecとFAISS、コード用にBM25（埋め込みはコードに向かない）、両方を組み合わせたハイブリッド検索。重要な知見：おそらく派手なベクターDBは不要 - SQLite FTS5や普通のトライグラム検索の方が特定のユースケースには効く。
***** Take
HNは半年ごとにgrepがまだ使えることを再発見する。「RAGどうやる」の本当の答えは「本当にRAGが必要なのか、それともAIをやってる気分になりたいだけか」だ。
***** Comments
- LLMにODataクエリインターフェースを持つツールを与えるのがうまくいった。仕事で4万行のExcelシートがあるが、LLMで素早く確実に分析できた。
- ベクター生成は最初Meta-LLama-3-8BをPythonとTransformersでRTX-A6000で動かした。速いがうるさく500W消費。M1 UltraとMLXに切り替えたら同じ速度で発熱が減った。
- 複雑なドキュメントの多くはMarkdownファイル。github.com/tobi/qmdをおすすめする。こういったファイルを検索するシンプルなCLIツール。fzfより良い結果が出る。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Ask HN: 로컬에서 RAG 어떻게 하고 있나요?
***** TLDR
HN에서 로컬 RAG 설정을 논의한다. 주요 접근법: 벡터용으로 SQLite-vec과 FAISS, 코드용으로 BM25(임베딩은 코드에 안 좋음), 둘을 결합한 하이브리드 검색. 핵심 통찰: 화려한 벡터 DB는 아마 필요 없다 - SQLite FTS5나 단순 트라이그램 검색이 특정 사용 사례에는 더 잘 작동한다.
***** Take
HN은 6개월마다 grep이 아직 작동한다는 걸 재발견한다. 'RAG 어떻게 하나요'의 진짜 답은 '정말 RAG가 필요한 건가 아니면 AI 하는 기분만 내고 싶은 건가?'다.
***** Comments
- LLM에 OData 쿼리 인터페이스가 있는 도구를 주는 게 잘 됐다. 회사에 4만 행 엑셀 시트가 있는데 LLM이 빠르고 안정적으로 분석했다.
- 벡터 생성은 처음에 RTX-A6000에서 Python과 Transformers로 Meta-LLama-3-8B를 썼다. 빠르지만 시끄럽고 500W 소모. M1 Ultra에 MLX로 바꾸니 같은 속도에 발열이 줄었다.
- 복잡한 문서 대부분이 마크다운 파일이다. github.com/tobi/qmd를 추천한다. 이런 파일을 검색하는 간단한 CLI 도구다. fzf보다 결과가 좋다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Ask HN: ¿Cómo están haciendo RAG localmente?
***** TLDR
HN discute configuraciones locales de RAG. Enfoques principales: SQLite-vec y FAISS para vectores, BM25 para código (los embeddings son malos para código), búsqueda híbrida combinando ambos. Insight clave: probablemente no necesitas una DB vectorial fancy - SQLite FTS5 o búsqueda de trigramas simple funciona mejor para casos específicos.
***** Take
Cada seis meses HN redescubre que grep todavía funciona. La respuesta real a 'cómo hago RAG' es '¿realmente necesitas RAG o solo quieres sentir que estás haciendo IA?'
***** Comments
- Dar al LLM herramientas con interfaz de consulta OData me ha funcionado bien. En el trabajo tenemos una hoja Excel con 40k filas que el LLM pudo analizar rápida y confiablemente.
- Para generación de vectores empecé usando Meta-LLama-3-8B con Python y Transformers en una RTX-A6000. Rápido pero ruidoso y consume 500W. Cambié a M1 Ultra con MLX - misma velocidad, menos calor.
- La mayoría de mis documentos complejos son archivos Markdown. Recomiendo github.com/tobi/qmd. Es una herramienta CLI simple para buscar en este tipo de archivos. Mejores resultados que fzf.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Ask HN: Wie macht ihr RAG lokal?
***** TLDR
HN diskutiert lokale RAG-Setups. Top-Ansätze: SQLite-vec und FAISS für Vektoren, BM25 für Code (Embeddings sind schlecht für Code), Hybrid-Suche kombiniert beides. Wichtige Erkenntnis: Du brauchst wahrscheinlich keine fancy Vektor-DB - SQLite FTS5 oder einfache Trigramm-Suche funktioniert oft besser für spezifische Anwendungsfälle.
***** Take
Alle sechs Monate entdeckt HN wieder, dass grep noch funktioniert. Die echte Antwort auf 'wie mache ich RAG' ist 'brauchst du wirklich RAG oder willst du nur das Gefühl haben, KI zu machen?'
***** Comments
- Dem LLM Werkzeuge mit OData-Query-Interface zu geben hat bei mir gut funktioniert. Bei der Arbeit haben wir eine Excel-Tabelle mit 40k Zeilen, die das LLM schnell und zuverlässig analysieren konnte.
- Für Vektor-Generierung begann ich mit Meta-LLama-3-8B mit Python und Transformers auf einer RTX-A6000. Schnell aber laut und verbraucht 500W. Wechselte zu M1 Ultra mit MLX - gleiche Geschwindigkeit, weniger Hitze.
- Die meisten meiner komplexen Dokumente sind Markdown-Dateien. Ich empfehle github.com/tobi/qmd. Ein einfaches CLI-Tool zum Durchsuchen solcher Dateien. Bessere Ergebnisse als fzf.