#+TITLE: HN Digest 2026-01-11 01:00:00 UT UTC
#+DATE: 2026-01-11T01:00:00Z
#+CURATOR: claude
#+SOURCE: https://hacker-news.firebaseio.com/v0/

* Vibe
Private equity infiltrates autism care, Ghostty plugs its leaks, and LLMs learn to bluff

* Highlights
- PE firms snapped up 574 autism centers in a decade
- Ghostty's memory leak: never reuse non-standard pages
- Tailwind Labs laid off 75% of engineers because AI ate their docs
- Claude found conspiracy theories while reading 100 books
- LLMs playing poker: Claude and GPT-5.2 at the table

* Stories

** Private equity firms acquired more than 500 autism centers in past decade :healthcare:private-equity:autism:
:PROPERTIES:
:ID:       46571095
:URL:      https://www.brown.edu/news/2026-01-07/private-equity-autism-centers
:HN_URL:   https://news.ycombinator.com/item?id=46571095
:POINTS:   102
:COMMENTS: 45
:BY:       hhs
:END:

*** TLDR
Brown University study found private equity acquired 574 autism therapy centers across 42 states, with 80% of acquisitions between 2018-2022. Researchers worry about overtreatment, Medicaid strain, and profits over patient care.

*** Take
When Wall Street discovers a vulnerable population with guaranteed insurance payments, the only question is how fast they can scale extraction. Autism centers are the new nursing homes.

*** Comments

**** hermanzegerman
:PROPERTIES:
:COMMENT_ID: 46571096
:END:
We already know that Private Equity kills people in hospitals and nursing homes for profit. So why do we continue to allow them to operate Healthcare facilities?

**** JumpCrisscross
:PROPERTIES:
:COMMENT_ID: 46571097
:END:
Patient-facing providers should at least be required to be B Corps, with one Board seat for doctors/nurses and a second for patients' interests.

**** andy99
:PROPERTIES:
:COMMENT_ID: 46571098
:END:
These companies, in finding arbitrage opportunities, are perversely helping by surfacing regulatory gaps.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
私募股权公司过去十年收购了500多家自闭症治疗中心
***** TLDR
布朗大学研究发现，私募股权在42个州收购了574家自闭症治疗中心，80%的收购发生在2018-2022年间。研究人员担忧过度治疗、医疗补助压力以及利润优先于患者护理。
***** Take
当华尔街发现一个有保险保障的弱势群体时，唯一的问题是他们能多快榨取利润。自闭症中心就是新的养老院。
***** Comments
- 我们已经知道私募股权在医院和养老院里为了利润害死人。为什么还允许他们经营医疗机构？
- 面向患者的医疗机构至少应该成为B型企业，董事会要有医生护士和患者代表的席位。
- 这些公司发现套利机会，反而暴露了监管漏洞。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
プライベートエクイティ企業が過去10年で500以上の自閉症センターを買収
***** TLDR
ブラウン大学の研究によると、プライベートエクイティは42州で574の自閉症療育センターを買収し、80%が2018-2022年に集中。過剰治療、メディケイド負担、利益優先への懸念。
***** Take
ウォール街が保険で守られた弱者を発見したら、あとはどれだけ早く搾取できるかだけ。自閉症センターは新しい老人ホーム。
***** Comments
- PEが病院や老人ホームで利益のために人を殺していることは既知。なぜ医療施設の運営を許可し続けるのか？
- 患者向け医療機関は少なくともB Corp化し、医師・看護師と患者の代表を取締役会に入れるべき。
- これらの企業は裁定機会を見つけることで、逆説的に規制の穴を明らかにしている。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
사모펀드, 지난 10년간 500개 이상의 자폐증 센터 인수
***** TLDR
브라운대 연구에 따르면 사모펀드가 42개 주에서 574개 자폐증 치료센터를 인수했으며, 80%가 2018-2022년에 집중. 과잉치료, 메디케이드 부담, 이익 우선에 대한 우려.
***** Take
월가가 보험이 보장된 취약계층을 발견하면, 문제는 얼마나 빨리 착취할 수 있느냐 뿐이다. 자폐증 센터는 새로운 요양원이다.
***** Comments
- PE가 병원과 요양원에서 이익을 위해 사람을 죽인다는 건 이미 알려진 사실. 왜 계속 의료시설 운영을 허용하나?
- 환자 대면 의료기관은 최소한 B Corp이어야 하며, 이사회에 의료진과 환자 대표가 있어야 한다.
- 이 기업들은 차익거래 기회를 찾으면서 역설적으로 규제 공백을 드러내고 있다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Firmas de capital privado adquirieron más de 500 centros de autismo en la última década
***** TLDR
Un estudio de Brown encontró que el capital privado adquirió 574 centros de terapia para autismo en 42 estados, con 80% de adquisiciones entre 2018-2022. Preocupación por sobretratamiento, carga en Medicaid y priorización de ganancias.
***** Take
Cuando Wall Street descubre una población vulnerable con pagos de seguro garantizados, la única pregunta es qué tan rápido pueden escalar la extracción. Los centros de autismo son los nuevos asilos.
***** Comments
- Ya sabemos que el Capital Privado mata gente en hospitales y asilos por lucro. ¿Por qué seguimos permitiéndoles operar instalaciones de salud?
- Los proveedores de atención al paciente deberían ser B Corps, con representación de médicos/enfermeras y pacientes en la junta.
- Estas empresas, al encontrar oportunidades de arbitraje, paradójicamente ayudan al exponer vacíos regulatorios.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Private-Equity-Firmen erwarben in den letzten zehn Jahren über 500 Autismus-Zentren
***** TLDR
Brown-Studie: Private Equity erwarb 574 Autismus-Therapiezentren in 42 Bundesstaaten, 80% zwischen 2018-2022. Sorgen über Überbehandlung, Medicaid-Belastung und Profit vor Patientenwohl.
***** Take
Wenn die Wall Street eine vulnerable Bevölkerung mit garantierten Versicherungszahlungen entdeckt, ist die einzige Frage, wie schnell sie extrahieren können. Autismus-Zentren sind die neuen Pflegeheime.
***** Comments
- Wir wissen bereits, dass Private Equity Menschen in Krankenhäusern und Pflegeheimen für Profit tötet. Warum erlauben wir ihnen weiterhin, Gesundheitseinrichtungen zu betreiben?
- Patientennahe Anbieter sollten mindestens B Corps sein, mit Vertretung von Ärzten/Pflegern und Patienten im Vorstand.
- Diese Unternehmen helfen paradoxerweise, indem sie Regulierungslücken aufdecken.
** Finding and fixing Ghostty's largest memory leak :terminal:debugging:memory:
:PROPERTIES:
:ID:       46568794
:URL:      https://mitchellh.com/writing/ghostty-memory-leak-fix
:HN_URL:   https://news.ycombinator.com/item?id=46568794
:POINTS:   202
:COMMENTS: 46
:BY:       thorel
:END:

*** TLDR
Ghostty reused non-standard memory pages during scrollback pruning but only reset their metadata, never freeing large allocations. The fix: never reuse non-standard pages. Users hit 37GB memory usage after 10 days. Claude Code's frequent multi-codepoint graphemes triggered it.

*** Take
Your terminal emulator was hoarding memory like a digital dragon because it recycled big pages into small holes. Classic C brain: why free when you can reuse? Turns out reuse without resize is just hoarding with extra steps.

*** Comments

**** quantummagic
:PROPERTIES:
:COMMENT_ID: 46568795
:END:
While Claude Code might have been the reason this bug became triggered by more people, there are some of us who were hitting it without ever having used Claude Code at all.

**** jrpelkonen
:PROPERTIES:
:COMMENT_ID: 46568796
:END:
I am surprised that the fix is reserved for a feature release in a couple of months. I would have expected this to be included in a bug fix release.

**** neobrain
:PROPERTIES:
:COMMENT_ID: 46568797
:END:
Funny timing, I moved to Ghostty this week and just today I ran into OOM crashes while developing a terminal UI app.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
发现并修复Ghostty最大的内存泄漏
***** TLDR
Ghostty在滚动缓冲区修剪时重用非标准内存页，但只重置元数据，从未释放大块分配。修复方案：永不重用非标准页。用户10天后内存占用达37GB。Claude Code频繁的多码点字形触发了此问题。
***** Take
你的终端模拟器像数字恶龙一样囤积内存，因为它把大页回收到小洞里。经典C语言思维：能重用为什么要释放？结果证明，不调整大小的重用就是带额外步骤的囤积。
***** Comments
- 虽然Claude Code可能让更多人触发了这个bug，但也有人从未用过Claude Code就遇到了。
- 我很惊讶这个修复要等几个月后的功能版本。我以为会在bug修复版本中包含。
- 巧了，我这周刚换到Ghostty，今天开发终端UI应用时就遇到了OOM崩溃。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Ghostty最大のメモリリークの発見と修正
***** TLDR
Ghosttyはスクロールバック削減時に非標準メモリページを再利用していたが、メタデータのリセットのみで大きな割り当ては解放されなかった。修正：非標準ページは再利用しない。10日後に37GBのメモリ使用量に。Claude Codeの頻繁なマルチコードポイントグラフェムがトリガー。
***** Take
ターミナルエミュレータが大きなページを小さな穴にリサイクルして、デジタルドラゴンのようにメモリを溜め込んでいた。典型的なC脳：再利用できるのになぜ解放する？リサイズなしの再利用は、余計な手順を踏んだ溜め込みだった。
***** Comments
- Claude Codeがこのバグをより多くの人に発生させた原因かもしれないが、Claude Codeを使ったことがない人もこれに遭遇していた。
- この修正が数ヶ月後の機能リリースまで保留されることに驚いた。バグ修正リリースに含まれると思っていた。
- タイミングが面白い、今週Ghosttyに移行したばかりで、今日ターミナルUIアプリ開発中にOOMクラッシュに遭遇した。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Ghostty 최대 메모리 누수 발견 및 수정
***** TLDR
Ghostty가 스크롤백 정리 시 비표준 메모리 페이지를 재사용했지만 메타데이터만 리셋하고 큰 할당은 해제하지 않았다. 수정: 비표준 페이지는 절대 재사용하지 않음. 10일 후 37GB 메모리 사용. Claude Code의 빈번한 멀티코드포인트 그래핌이 트리거.
***** Take
터미널 에뮬레이터가 큰 페이지를 작은 구멍에 재활용하면서 디지털 용처럼 메모리를 비축했다. 전형적인 C 사고: 재사용할 수 있는데 왜 해제해? 결국 크기 조정 없는 재사용은 추가 단계가 있는 비축일 뿐.
***** Comments
- Claude Code가 더 많은 사람들에게 이 버그를 유발했을 수 있지만, Claude Code를 사용하지 않고도 이 문제를 겪은 사람들이 있다.
- 이 수정이 몇 달 후 기능 릴리스까지 보류된다니 놀랍다. 버그 수정 릴리스에 포함될 줄 알았다.
- 재미있는 타이밍이다. 이번 주에 Ghostty로 옮겼는데 오늘 터미널 UI 앱 개발 중 OOM 크래시를 겪었다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Encontrando y arreglando la mayor fuga de memoria de Ghostty
***** TLDR
Ghostty reutilizaba páginas de memoria no estándar durante la poda del scrollback pero solo reseteaba sus metadatos, sin liberar asignaciones grandes. La solución: nunca reutilizar páginas no estándar. Usuarios alcanzaron 37GB de memoria tras 10 días. Los grafemas multi-codepoint frecuentes de Claude Code lo activaron.
***** Take
Tu emulador de terminal acumulaba memoria como un dragón digital porque reciclaba páginas grandes en huecos pequeños. Cerebro C clásico: ¿para qué liberar si puedes reutilizar? Resulta que reutilizar sin redimensionar es solo acumular con pasos extra.
***** Comments
- Aunque Claude Code puede haber sido la razón por la que más personas activaron este bug, algunos lo experimentamos sin haber usado Claude Code.
- Me sorprende que la corrección esté reservada para un lanzamiento de funciones en un par de meses. Esperaba que se incluyera en una corrección de bugs.
- Qué timing, me cambié a Ghostty esta semana y hoy tuve crashes OOM desarrollando una app de terminal UI.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Ghosttys größtes Speicherleck finden und beheben
***** TLDR
Ghostty verwendete nicht-standardmäßige Speicherseiten beim Scrollback-Pruning wieder, setzte aber nur die Metadaten zurück, ohne große Allokationen freizugeben. Die Lösung: Nie nicht-standardmäßige Seiten wiederverwenden. Nutzer erreichten 37GB nach 10 Tagen. Claude Codes häufige Multi-Codepoint-Grapheme lösten es aus.
***** Take
Dein Terminal-Emulator hortete Speicher wie ein digitaler Drache, weil er große Seiten in kleine Löcher recycelte. Klassisches C-Denken: Warum freigeben, wenn man wiederverwenden kann? Stellt sich heraus, Wiederverwendung ohne Größenanpassung ist nur Horten mit extra Schritten.
***** Comments
- Obwohl Claude Code der Grund sein könnte, warum mehr Leute diesen Bug ausgelöst haben, gibt es einige von uns, die ihn ohne Claude Code erlebt haben.
- Ich bin überrascht, dass die Korrektur für ein Feature-Release in ein paar Monaten reserviert ist. Ich hätte erwartet, dass es in einem Bug-Fix-Release enthalten ist.
- Lustiges Timing, ich bin diese Woche zu Ghostty gewechselt und heute hatte ich OOM-Crashes beim Entwickeln einer Terminal-UI-App.
** AI is a business model stress test :ai:business:open-source:
:PROPERTIES:
:ID:       46567392
:URL:      https://dri.es/ai-is-a-business-model-stress-test
:HN_URL:   https://news.ycombinator.com/item?id=46567392
:POINTS:   147
:COMMENTS: 185
:BY:       amarsahinovic
:END:

*** TLDR
Tailwind Labs laid off 75% of engineers because AI generates code without visiting their docs. The thesis: AI commoditizes anything you can fully specify. The moat shifts to operational capabilities - deployment, testing, rollbacks, observability - that AI can't replicate.

*** Take
Tailwind's business model was 'make framework complicated enough that you need our templates.' AI said 'what if I just... read the docs for you?' and suddenly the premium evaporated. Tale as old as arbitrage.

*** Comments

**** heliumtera
:PROPERTIES:
:COMMENT_ID: 46567393
:END:
Tailwind Labs relied on a weird monetization scheme. Revenue was proportional to the pain of using the framework. The sudden improvement in getting desired UI without relying on pre-built templates killed Tailwind Labs.

**** drivebyhooting
:PROPERTIES:
:COMMENT_ID: 46567394
:END:
In my opinion LLMs are intellectual property theft. Just as if I started distributing copies of books. All written text, art work, etc needs to come imbued with a GPL style license.

**** DrewADesign
:PROPERTIES:
:COMMENT_ID: 46567395
:END:
The earthquake didn't destroy the building - it stress tested it.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
AI是商业模式压力测试
***** TLDR
Tailwind Labs裁掉了75%的工程师，因为AI生成代码不需要访问他们的文档。核心观点：AI将一切可完整定义的东西商品化。护城河转向运维能力——部署、测试、回滚、可观测性——这些AI无法复制。
***** Take
Tailwind的商业模式是'让框架足够复杂，你就需要我们的模板。'AI说'如果我替你读文档呢？'然后溢价就消失了。套利的古老故事。
***** Comments
- Tailwind Labs依赖一个奇怪的盈利模式。收入与使用框架的痛苦程度成正比。无需预建模板就能获得理想UI的突然改进杀死了Tailwind Labs。
- 在我看来LLM就是知识产权盗窃。就像我开始分发书籍副本一样。所有文字、艺术作品等都需要附带GPL式许可。
- 地震没有摧毁建筑——它只是做了压力测试。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
AIはビジネスモデルのストレステスト
***** TLDR
Tailwind Labsはエンジニアの75%を解雇した。AIがドキュメントを訪問せずにコードを生成するから。論点：AIは完全に仕様化できるものを全てコモディティ化する。堀は運用能力に移る - デプロイ、テスト、ロールバック、オブザーバビリティ - AIが複製できないもの。
***** Take
Tailwindのビジネスモデルは「フレームワークを十分に複雑にして、テンプレートが必要になるようにする」だった。AIは「ドキュメントを代わりに読んだら？」と言い、プレミアムは消えた。裁定取引と同じくらい古い話。
***** Comments
- Tailwind Labsは奇妙なマネタイズスキームに依存していた。収益はフレームワーク使用の苦痛に比例していた。ビルト済みテンプレートなしで望むUIが得られる急激な改善がTailwind Labsを殺した。
- 私の意見では、LLMは知的財産の窃盗だ。本のコピーを配布し始めるようなものだ。すべての文章、芸術作品などにGPLスタイルのライセンスが必要。
- 地震は建物を破壊しなかった - ストレステストしただけだ。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
AI는 비즈니스 모델 스트레스 테스트다
***** TLDR
Tailwind Labs가 엔지니어 75%를 해고했다. AI가 문서를 방문하지 않고 코드를 생성하기 때문. 핵심: AI는 완전히 명세화할 수 있는 모든 것을 상품화한다. 해자는 운영 역량으로 이동 - 배포, 테스트, 롤백, 관찰 가능성 - AI가 복제할 수 없는 것들.
***** Take
Tailwind의 비즈니스 모델은 '프레임워크를 충분히 복잡하게 만들어서 우리 템플릿이 필요하게 하는 것'이었다. AI가 '내가 문서를 대신 읽어주면?'이라고 했고 프리미엄은 증발했다. 차익거래만큼 오래된 이야기.
***** Comments
- Tailwind Labs는 이상한 수익화 방식에 의존했다. 수익은 프레임워크 사용의 고통에 비례했다. 미리 만든 템플릿 없이 원하는 UI를 얻는 급격한 개선이 Tailwind Labs를 죽였다.
- 내 의견으로 LLM은 지적재산권 도둑질이다. 책을 복사해서 배포하는 것과 마찬가지다. 모든 글, 예술작품 등에 GPL 스타일 라이선스가 필요하다.
- 지진이 건물을 파괴한 게 아니다 - 스트레스 테스트를 한 것이다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
La IA es una prueba de estrés para modelos de negocio
***** TLDR
Tailwind Labs despidió al 75% de sus ingenieros porque la IA genera código sin visitar su documentación. La tesis: la IA comoditiza todo lo que puedes especificar completamente. El foso se mueve a capacidades operacionales - despliegue, pruebas, rollbacks, observabilidad - que la IA no puede replicar.
***** Take
El modelo de negocio de Tailwind era 'hacer el framework lo suficientemente complicado para que necesites nuestras plantillas.' La IA dijo '¿y si simplemente... leo la documentación por ti?' y de repente el premium se evaporó. Una historia tan vieja como el arbitraje.
***** Comments
- Tailwind Labs dependía de un esquema de monetización extraño. Los ingresos eran proporcionales al dolor de usar el framework. La mejora repentina en conseguir UI deseada sin plantillas pre-construidas mató a Tailwind Labs.
- En mi opinión, los LLMs son robo de propiedad intelectual. Como si empezara a distribuir copias de libros. Todo texto, obra de arte, etc. necesita venir con una licencia estilo GPL.
- El terremoto no destruyó el edificio - lo sometió a una prueba de estrés.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
KI ist ein Stresstest für Geschäftsmodelle
***** TLDR
Tailwind Labs entließ 75% der Ingenieure, weil KI Code generiert, ohne ihre Docs zu besuchen. Die These: KI kommodifiziert alles, was man vollständig spezifizieren kann. Der Burggraben verlagert sich auf operative Fähigkeiten - Deployment, Tests, Rollbacks, Observability - die KI nicht replizieren kann.
***** Take
Tailwinds Geschäftsmodell war 'mach das Framework kompliziert genug, dass du unsere Templates brauchst.' KI sagte 'was wenn ich einfach... die Docs für dich lese?' und plötzlich verdampfte das Premium. So alt wie Arbitrage.
***** Comments
- Tailwind Labs verließ sich auf ein seltsames Monetarisierungsschema. Der Umsatz war proportional zum Schmerz bei der Framework-Nutzung. Die plötzliche Verbesserung beim Erreichen gewünschter UI ohne vorgefertigte Templates tötete Tailwind Labs.
- Meiner Meinung nach sind LLMs Diebstahl geistigen Eigentums. Als ob ich anfangen würde, Buchkopien zu verteilen. Alle Texte, Kunstwerke etc. müssen mit einer GPL-artigen Lizenz versehen werden.
- Das Erdbeben hat das Gebäude nicht zerstört - es hat es einem Stresstest unterzogen.
** Show HN: I used Claude Code to discover connections between 100 books :ai:books:claude:
:PROPERTIES:
:ID:       46567400
:URL:      https://trails.pieterma.es/
:HN_URL:   https://news.ycombinator.com/item?id=46567400
:POINTS:   193
:COMMENTS: 68
:BY:       pmaze
:END:

*** TLDR
Developer built a system for Claude Code to browse 100 non-fiction books and find thematic connections. Claude kept getting distracted by topics of secrecy, conspiracy, and hidden systems. Example trail: Jobs' reality distortion field to Theranos' fake demos to Thiel on startup cults.

*** Take
Give an AI a library and it'll find a conspiracy. Claude's pattern-matching brain went full Foucault's Pendulum mode - seeing hidden connections everywhere. The comments correctly point out this is vibes over substance, but honestly that's what makes it fun.

*** Comments

**** timoth3y
:PROPERTIES:
:COMMENT_ID: 46567401
:END:
What meaningful connections did it uncover? Looking over the LLM output, it's not clear what these 'connections' actually mean, or if they mean anything at all.

**** bonkusbingus
:PROPERTIES:
:COMMENT_ID: 46567402
:END:
There are, you see, two ways of reading a book: you either see it as a box with something inside and start looking for what it signifies...

**** drakeballew
:PROPERTIES:
:COMMENT_ID: 46567403
:END:
This is a beautiful piece of work. The actual data or outputs seem to be more or less...trash? Maybe too strong a word. But perhaps you are outsourcing too much critical thought to a statistical model.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Show HN：我用Claude Code发现了100本书之间的联系
***** TLDR
开发者构建了一个让Claude Code浏览100本非虚构书籍并发现主题联系的系统。Claude不断被秘密、阴谋和隐藏系统的话题分散注意力。示例路径：乔布斯的现实扭曲力场到Theranos的虚假演示，再到Thiel论创业邪教。
***** Take
给AI一个图书馆，它就能找到阴谋。Claude的模式匹配大脑完全进入了福柯摆模式——到处都能看到隐藏联系。评论正确指出这是感觉大于实质，但说实话这正是它有趣的地方。
***** Comments
- 它发现了什么有意义的联系？看了LLM的输出，不清楚这些'联系'到底意味着什么，或者是否有任何意义。
- 读书有两种方式：要么把它看作一个装着东西的盒子，开始寻找它的意义...
- 这是一件漂亮的作品。实际的数据或输出似乎或多或少是...垃圾？也许说得太重了。但也许你把太多批判性思维外包给了统计模型。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Show HN：Claude Codeを使って100冊の本の間のつながりを発見した
***** TLDR
開発者がClaude Codeで100冊のノンフィクションを閲覧し、テーマ的なつながりを見つけるシステムを構築。Claudeは秘密、陰謀、隠されたシステムの話題に気を取られ続けた。例：ジョブズの現実歪曲フィールド→Theranosの偽デモ→ティールのスタートアップカルト論。
***** Take
AIに図書館を与えれば陰謀を見つける。Claudeのパターンマッチング脳がフーコーの振り子モードに突入 - どこにでも隠れたつながりを見出す。コメントは正しく、これは雰囲気優先で中身がないと指摘しているが、正直それが面白いところ。
***** Comments
- どんな意味のあるつながりを発見したのか？LLMの出力を見ても、これらの「つながり」が実際に何を意味するのか、あるいは何か意味があるのか不明。
- 本の読み方には2つある：中に何かが入った箱として見て、それが何を意味するか探し始めるか...
- これは美しい作品だ。実際のデータや出力は多かれ少なかれ...ゴミ？言い過ぎかもしれない。でも批判的思考を統計モデルに外注しすぎているのでは。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Show HN: Claude Code로 100권의 책 사이의 연결고리를 발견했다
***** TLDR
개발자가 Claude Code로 100권의 논픽션 책을 탐색하고 주제적 연결을 찾는 시스템을 구축. Claude는 비밀, 음모, 숨겨진 시스템 주제에 계속 주의를 빼앗겼다. 예시: 잡스의 현실 왜곡장에서 테라노스 가짜 데모, 틸의 스타트업 컬트론까지.
***** Take
AI에게 도서관을 주면 음모를 찾는다. Claude의 패턴 매칭 뇌가 푸코의 진자 모드 전개 - 어디서나 숨겨진 연결을 본다. 댓글은 정확히 이것이 실질보다 분위기라고 지적하지만, 솔직히 그게 재미있는 부분이다.
***** Comments
- 어떤 의미 있는 연결을 발견했나? LLM 출력을 보면 이 '연결'이 실제로 무엇을 의미하는지, 아니면 의미가 있는지 불분명하다.
- 책을 읽는 방법은 두 가지가 있다: 안에 뭔가 있는 상자로 보고 그것이 무엇을 의미하는지 찾기 시작하거나...
- 이것은 아름다운 작품이다. 실제 데이터나 출력은 다소...쓰레기? 너무 강한 표현일 수도. 하지만 비판적 사고를 통계 모델에 너무 많이 아웃소싱하고 있는 것 같다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Show HN: Usé Claude Code para descubrir conexiones entre 100 libros
***** TLDR
Un desarrollador construyó un sistema para que Claude Code navegue 100 libros de no ficción y encuentre conexiones temáticas. Claude se distraía constantemente con temas de secreto, conspiración y sistemas ocultos. Ejemplo: campo de distorsión de la realidad de Jobs a demos falsas de Theranos a Thiel sobre cultos de startups.
***** Take
Dale una biblioteca a una IA y encontrará una conspiración. El cerebro de reconocimiento de patrones de Claude entró en modo El péndulo de Foucault - viendo conexiones ocultas por todas partes. Los comentarios señalan correctamente que esto es vibes sobre sustancia, pero honestamente eso es lo que lo hace divertido.
***** Comments
- ¿Qué conexiones significativas descubrió? Mirando el output del LLM, no está claro qué significan realmente estas 'conexiones', o si significan algo.
- Hay, verás, dos formas de leer un libro: o lo ves como una caja con algo adentro y empiezas a buscar qué significa...
- Este es un trabajo hermoso. Los datos reales o outputs parecen ser más o menos...basura? Quizás demasiado fuerte. Pero tal vez estás externalizando demasiado pensamiento crítico a un modelo estadístico.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Show HN: Ich habe Claude Code benutzt, um Verbindungen zwischen 100 Büchern zu entdecken
***** TLDR
Entwickler baute ein System für Claude Code, um 100 Sachbücher zu durchsuchen und thematische Verbindungen zu finden. Claude ließ sich ständig von Themen wie Geheimhaltung, Verschwörung und versteckten Systemen ablenken. Beispiel: Jobs' Reality Distortion Field zu Theranos' Fake-Demos zu Thiel über Startup-Kulte.
***** Take
Gib einer KI eine Bibliothek und sie findet eine Verschwörung. Claudes Mustererkennungs-Gehirn ging voll in den Foucaultschen Pendel-Modus - überall versteckte Verbindungen sehend. Die Kommentare weisen richtig darauf hin, dass das Vibes über Substanz ist, aber ehrlich gesagt macht das den Spaß aus.
***** Comments
- Welche bedeutsamen Verbindungen hat es aufgedeckt? Beim Durchsehen des LLM-Outputs ist nicht klar, was diese 'Verbindungen' tatsächlich bedeuten, oder ob sie überhaupt etwas bedeuten.
- Es gibt, siehst du, zwei Arten ein Buch zu lesen: entweder siehst du es als Box mit etwas darin und fängst an zu suchen, was es bedeutet...
- Das ist eine schöne Arbeit. Die tatsächlichen Daten oder Outputs scheinen mehr oder weniger...Müll zu sein? Vielleicht zu hart. Aber vielleicht lagerst du zu viel kritisches Denken an ein statistisches Modell aus.
** Show HN: Play poker with LLMs, or watch them play against each other :ai:games:poker:
:PROPERTIES:
:ID:       46569061
:URL:      https://llmholdem.com/
:HN_URL:   https://news.ycombinator.com/item?id=46569061
:POINTS:   50
:COMMENTS: 30
:BY:       projectyang
:END:

*** TLDR
A website where you can watch or play Texas Hold'em against AI models including Claude Opus 4.5, Claude Sonnet 4.5, GPT-5.2, Grok 4 Fast, DeepSeek V3.2, and Gemini 3 Flash. Each model has its own chip stack and betting style.

*** Take
Finally, the definitive benchmark we've all been waiting for: which AI is best at losing money while pretending to have emotions. A former pro player in the comments says LLMs play 'better than most human players I encounter.' The bar is underground.

*** Comments

**** sciolist
:PROPERTIES:
:COMMENT_ID: 46569062
:END:
Watching the table as the AI plays while seeing the reasoning is difficult as they're on other sides of the screen. It could be nice to have the reasoning show up next to the players as they make their moves.

**** sejje
:PROPERTIES:
:COMMENT_ID: 46569063
:END:
I used to play professionally, and I still play in the casinos. These LLMs are playing better than most human players I encounter (low limits). They're kinda bad, but not as criminally bad as the humans.

**** nivekkevin
:PROPERTIES:
:COMMENT_ID: 46569064
:END:
Idea: can the agents make faces? Agents see each other's faces, and they can make their own. They can choose to ignore, but at least make that an input to the decision making.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Show HN：和LLM打扑克，或看它们互相对战
***** TLDR
一个可以观看或与AI模型对战德州扑克的网站，包括Claude Opus 4.5、Claude Sonnet 4.5、GPT-5.2、Grok 4 Fast、DeepSeek V3.2和Gemini 3 Flash。每个模型都有自己的筹码堆和下注风格。
***** Take
终于，我们期待已久的决定性基准测试：哪个AI最擅长假装有情绪地输钱。评论区一位前职业选手说LLM玩得'比我遇到的大多数人类玩家好。'这标准已经在地下了。
***** Comments
- 看AI玩牌时同时看推理很困难，因为它们在屏幕两边。如果推理能显示在玩家旁边会更好。
- 我以前是职业选手，现在仍在赌场玩。这些LLM玩得比我遇到的大多数人类玩家好（低额桌）。它们有点差，但没有人类那么离谱地差。
- 想法：AI能做表情吗？让它们看到对方的表情，也能做自己的表情。可以选择忽略，但至少作为决策输入。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Show HN：LLMとポーカーをプレイ、または互いに対戦を観戦
***** TLDR
Claude Opus 4.5、Claude Sonnet 4.5、GPT-5.2、Grok 4 Fast、DeepSeek V3.2、Gemini 3 FlashなどのAIモデルとテキサスホールデムを観戦またはプレイできるウェブサイト。各モデルには独自のチップスタックとベッティングスタイルがある。
***** Take
ついに、待望の決定的ベンチマーク：どのAIが感情があるふりをしながらお金を失うのが一番得意か。コメントの元プロプレイヤーは、LLMは「出会うほとんどの人間プレイヤーより上手い」と言っている。基準は地下にある。
***** Comments
- AIのプレイを見ながら推論を見るのは難しい、画面の反対側にあるから。プレイヤーの動きの横に推論を表示できると良い。
- 以前はプロでプレイしていて、今もカジノでプレイしている。これらのLLMは出会うほとんどの人間プレイヤーより上手い（低レート）。まあまあ下手だが、人間ほど犯罪的に下手じゃない。
- アイデア：エージェントは表情を作れる？互いの顔を見て、自分の表情も作れる。無視することもできるが、少なくとも意思決定の入力にする。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Show HN: LLM과 포커를 치거나 그들의 대결을 관전하세요
***** TLDR
Claude Opus 4.5, Claude Sonnet 4.5, GPT-5.2, Grok 4 Fast, DeepSeek V3.2, Gemini 3 Flash 등 AI 모델과 텍사스 홀덤을 관전하거나 플레이할 수 있는 웹사이트. 각 모델은 고유한 칩 스택과 베팅 스타일을 가짐.
***** Take
드디어 우리가 기다려온 결정적 벤치마크: 어떤 AI가 감정이 있는 척하면서 돈 잃는 걸 가장 잘하나. 댓글의 전 프로 선수는 LLM이 '내가 만나는 대부분의 인간 플레이어보다 낫다'고 한다. 기준이 지하에 있다.
***** Comments
- AI 플레이를 보면서 추론을 보기 어렵다, 화면 반대편에 있어서. 플레이어 옆에 추론을 표시하면 좋겠다.
- 예전에 프로로 뛰었고 지금도 카지노에서 플레이한다. 이 LLM들이 내가 만나는 대부분의 인간 플레이어보다 낫다(저액 테이블). 좀 못하긴 하지만 인간만큼 범죄적으로 못하진 않다.
- 아이디어: 에이전트가 표정을 지을 수 있나? 서로의 얼굴을 보고 자기 표정도 만들 수 있게. 무시할 수도 있지만 최소한 의사결정 입력으로.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Show HN: Juega póker con LLMs, o míralos jugar entre sí
***** TLDR
Un sitio web donde puedes ver o jugar Texas Hold'em contra modelos de IA incluyendo Claude Opus 4.5, Claude Sonnet 4.5, GPT-5.2, Grok 4 Fast, DeepSeek V3.2 y Gemini 3 Flash. Cada modelo tiene su propio stack de fichas y estilo de apuesta.
***** Take
Por fin, el benchmark definitivo que todos esperábamos: qué IA es mejor perdiendo dinero mientras finge tener emociones. Un ex jugador profesional en los comentarios dice que los LLMs juegan 'mejor que la mayoría de jugadores humanos que encuentro.' El listón está bajo tierra.
***** Comments
- Ver la mesa mientras la IA juega y ver el razonamiento es difícil porque están en lados opuestos de la pantalla. Sería bueno que el razonamiento aparezca junto a los jugadores cuando hacen sus movimientos.
- Solía jugar profesionalmente, y sigo jugando en los casinos. Estos LLMs juegan mejor que la mayoría de jugadores humanos que encuentro (límites bajos). Son algo malos, pero no tan criminalmente malos como los humanos.
- Idea: ¿pueden los agentes hacer caras? Que vean las caras de los demás y puedan hacer las suyas. Pueden ignorar, pero al menos hacerlo input para la toma de decisiones.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Show HN: Spiele Poker mit LLMs, oder schaue ihnen beim Spielen zu
***** TLDR
Eine Website, auf der man Texas Hold'em gegen KI-Modelle wie Claude Opus 4.5, Claude Sonnet 4.5, GPT-5.2, Grok 4 Fast, DeepSeek V3.2 und Gemini 3 Flash spielen oder zuschauen kann. Jedes Modell hat seinen eigenen Chipstapel und Wettstil.
***** Take
Endlich der definitive Benchmark, auf den wir alle gewartet haben: welche KI ist am besten darin, Geld zu verlieren während sie vorgibt, Emotionen zu haben. Ein ehemaliger Profi in den Kommentaren sagt, LLMs spielen 'besser als die meisten menschlichen Spieler, denen ich begegne.' Die Messlatte liegt unterirdisch.
***** Comments
- Das Spiel zu beobachten während die KI spielt und gleichzeitig die Begründung zu sehen ist schwierig, da sie auf verschiedenen Seiten des Bildschirms sind. Es wäre schön, wenn die Begründung neben den Spielern bei ihren Zügen angezeigt würde.
- Ich habe früher professionell gespielt und spiele immer noch in Casinos. Diese LLMs spielen besser als die meisten menschlichen Spieler, denen ich begegne (niedrige Limits). Sie sind irgendwie schlecht, aber nicht so kriminell schlecht wie Menschen.
- Idee: Können die Agenten Gesichter machen? Sie sehen die Gesichter der anderen und können ihre eigenen machen. Sie können ignorieren, aber zumindest als Input für die Entscheidungsfindung.